{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Oana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class InferSent(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(InferSent, self).__init__()\n",
    "        self.bsize = config['bsize']\n",
    "        self.word_emb_dim = config['word_emb_dim']\n",
    "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
    "        self.pool_type = config['pool_type']\n",
    "        self.dpout_model = config['dpout_model']\n",
    "        self.version = 1 if 'version' not in config else config['version']\n",
    "\n",
    "        self.enc_lstm = nn.LSTM(\n",
    "            input_size=self.word_emb_dim,\n",
    "            hidden_size=self.enc_lstm_dim,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            dropout=self.dpout_model\n",
    "        )\n",
    "\n",
    "        assert self.version in [1, 2]\n",
    "        if self.version == 1:\n",
    "            self.bos = '<s>'\n",
    "            self.eos = '</s>'\n",
    "            self.max_pad = True\n",
    "            self.moses_tok = False\n",
    "        elif self.version == 2:\n",
    "            self.bos = '<p>'\n",
    "            self.eos = '</p>'\n",
    "            self.max_pad = False\n",
    "            self.moses_tok = True\n",
    "\n",
    "        # Strat de regresie pentru similaritate\n",
    "        self.regressor = nn.Linear(2 * self.enc_lstm_dim * 2, 1)  # 2*lstm_dim * 2 pentru concatenarea premisei și hypothesis\n",
    "\n",
    "    def is_cuda(self):\n",
    "        # Verifică dacă modelul este pe GPU\n",
    "        return next(self.parameters()).is_cuda\n",
    "\n",
    "    def forward(self, sent_tuple):\n",
    "        sent, sent_len = sent_tuple  # sent: (batch_size, seq_len, emb_dim); sent_len: (batch_size)\n",
    "\n",
    "        # Sort by length in descending order\n",
    "        sent_len_sorted, idx_sort = torch.sort(sent_len, descending=True)\n",
    "        sent_sorted = sent.index_select(0, idx_sort)\n",
    "\n",
    "        # Pack the sequence\n",
    "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent_sorted, sent_len_sorted.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        sent_output_packed, _ = self.enc_lstm(sent_packed)  # sent_output_packed: PackedSequence; _ : hidden state\n",
    "\n",
    "        # Unpack the sequence\n",
    "        sent_output, _ = nn.utils.rnn.pad_packed_sequence(sent_output_packed, batch_first=True)  # sent_output: (batch_size, seq_len, 2*enc_lstm_dim)\n",
    "\n",
    "        # Unsort to original order\n",
    "        _, idx_unsort = torch.sort(idx_sort, descending=False)\n",
    "        sent_output = sent_output.index_select(0, idx_unsort)\n",
    "        sent_len_sorted = sent_len_sorted.index_select(0, idx_unsort)\n",
    "\n",
    "        # Pooling\n",
    "        if self.pool_type == \"mean\":\n",
    "            # Calculate the sum over the sequence dimension and divide by the lengths\n",
    "            sent_len_unsorted = sent_len.index_select(0, idx_unsort).float().unsqueeze(1)  # (batch_size, 1)\n",
    "            emb = torch.sum(sent_output, dim=1) / sent_len_unsorted  # (batch_size, 2*enc_lstm_dim)\n",
    "        elif self.pool_type == \"max\":\n",
    "            if not self.max_pad:\n",
    "                sent_output[sent_output == 0] = -1e9\n",
    "            emb, _ = torch.max(sent_output, dim=1)  # (batch_size, 2*enc_lstm_dim)\n",
    "\n",
    "        return emb\n",
    "\n",
    "    def encode_sentence_pair(self, premise_tuple, hypothesis_tuple):\n",
    "        encoded_premise = self.forward(premise_tuple)\n",
    "        encoded_hypothesis = self.forward(hypothesis_tuple)\n",
    "        combined = torch.cat((encoded_premise, encoded_hypothesis), dim=1)  # (batch_size, 4*enc_lstm_dim)\n",
    "        return combined\n",
    "\n",
    "    def regress_similarity(self, combined):\n",
    "        similarity = self.regressor(combined)\n",
    "        return similarity.squeeze(1)  # Returnează un tensor de dimensiune (batch_size)\n",
    "\n",
    "    def set_w2v_path(self, w2v_path):\n",
    "        self.w2v_path = w2v_path\n",
    "\n",
    "    def get_word_dict(self, sentences, tokenize=True):\n",
    "        # Crează vocabularul de cuvinte\n",
    "        word_dict = {}\n",
    "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = ''\n",
    "        word_dict[self.bos] = ''\n",
    "        word_dict[self.eos] = ''\n",
    "        return word_dict\n",
    "\n",
    "    def get_w2v(self, word_dict):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # Crează word_vec cu vectori w2v\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                split_line = line.strip().split(' ')\n",
    "                word = split_line[0]\n",
    "                vec = np.array([float(val) for val in split_line[1:]], dtype='float32')\n",
    "                if word in word_dict:\n",
    "                    word_vec[word] = vec\n",
    "        print('Found %s/%s words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
    "        return word_vec\n",
    "\n",
    "    def get_w2v_k(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        # Crează word_vec cu primii K vectori w2v\n",
    "        k = 0\n",
    "        word_vec = {}\n",
    "        with open(self.w2v_path, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
    "                    break\n",
    "                split_line = line.strip().split(' ')\n",
    "                word = split_line[0]\n",
    "                vec = np.array([float(val) for val in split_line[1:]], dtype='float32')\n",
    "                if k <= K or word in [self.bos, self.eos]:\n",
    "                    word_vec[word] = vec\n",
    "                    k += 1\n",
    "        return word_vec\n",
    "\n",
    "    def build_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "        self.word_vec = self.get_w2v(word_dict)\n",
    "        print('Vocab size : %s' % (len(self.word_vec)))\n",
    "\n",
    "    def build_vocab_k_words(self, K):\n",
    "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
    "        self.word_vec = self.get_w2v_k(K)\n",
    "        print('Vocab size : %s' % (len(self.word_vec)))\n",
    "\n",
    "    def update_vocab(self, sentences, tokenize=True):\n",
    "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
    "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
    "        word_dict = self.get_word_dict(sentences, tokenize)\n",
    "\n",
    "        # Păstrează doar cuvintele noi\n",
    "        new_words = {word: '' for word in word_dict if word not in self.word_vec}\n",
    "        if new_words:\n",
    "            new_word_vec = self.get_w2v(new_words)\n",
    "            self.word_vec.update(new_word_vec)\n",
    "            print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
    "        else:\n",
    "            print('No new words to add.')\n",
    "\n",
    "    \n",
    "    def get_batch(self, batch):\n",
    "        # Determină dimensiunile batch-ului\n",
    "        batch_size = len(batch)\n",
    "        max_len = max(len(s) for s in batch)\n",
    "        \n",
    "        # Inițializează un array de numpy pentru embed\n",
    "        embed = np.zeros((batch_size, max_len, self.word_emb_dim), dtype=np.float32)\n",
    "        \n",
    "        for i, sentence in enumerate(batch):\n",
    "            for j, word in enumerate(sentence):\n",
    "                embed[i, j, :] = self.word_vec.get(word, self.word_vec.get('<unk>', np.zeros(self.word_emb_dim)))\n",
    "        \n",
    "        return torch.from_numpy(embed)  # Returnează un tensor PyTorch\n",
    "\n",
    "    def tokenize(self, s):\n",
    "        # Folosește spaCy pentru tokenizare\n",
    "        return preprocess_sentence_spacy(s)\n",
    "\n",
    "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
    "        # Adaugă <s> și </s> și tokenizează dacă este necesar\n",
    "        sentences = [\n",
    "            [self.bos] + s + [self.eos] for s in sentences\n",
    "        ]\n",
    "        n_w = np.sum([len(x) for x in sentences])\n",
    "\n",
    "        # Filtrează cuvintele fără vectori w2v\n",
    "        for i in range(len(sentences)):\n",
    "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
    "            if not s_f:\n",
    "                import warnings\n",
    "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. Replacing by \"</s>\"..' % (sentences[i], i))\n",
    "                s_f = [self.eos]\n",
    "            sentences[i] = s_f\n",
    "\n",
    "        lengths = np.array([len(s) for s in sentences])\n",
    "        n_wk = np.sum(lengths)\n",
    "        if verbose:\n",
    "            print('Nb words kept : %s/%s (%.1f%%)' % (n_wk, n_w, 100.0 * n_wk / n_w))\n",
    "\n",
    "        # Sortează propozițiile după lungime descrescătoare\n",
    "        lengths_sorted, idx_sort = torch.sort(torch.tensor(lengths), descending=True)\n",
    "        sentences_sorted = [sentences[i] for i in idx_sort]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"First 5 sorted sentence lengths: {lengths_sorted[:5].tolist()}\")\n",
    "            print(f\"First 5 sorted sentences: {sentences_sorted[:5]}\")\n",
    "\n",
    "        return sentences_sorted, lengths_sorted.numpy(), idx_sort.numpy()\n",
    "\n",
    "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
    "        tic = time.time()\n",
    "        sentences_sorted, lengths_sorted, idx_sort = self.prepare_samples(\n",
    "                        sentences, bsize, tokenize, verbose)\n",
    "\n",
    "        embeddings = []\n",
    "        for stidx in range(0, len(sentences_sorted), bsize):\n",
    "            batch_sentences = sentences_sorted[stidx:stidx + bsize]\n",
    "            batch = self.get_batch(batch_sentences)\n",
    "            if self.is_cuda():\n",
    "                batch = batch.cuda()\n",
    "            lengths = lengths_sorted[stidx:stidx + bsize]\n",
    "            with torch.no_grad():\n",
    "                batch_output = self.forward((batch, torch.tensor(lengths).cuda() if self.is_cuda() else torch.tensor(lengths)))\n",
    "                embeddings.append(batch_output.cpu().numpy())\n",
    "        embeddings = np.vstack(embeddings)\n",
    "\n",
    "        # Unsort\n",
    "        idx_unsort = np.argsort(idx_sort)\n",
    "        embeddings = embeddings[idx_unsort]\n",
    "\n",
    "        if verbose:\n",
    "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
    "                    len(embeddings)/(time.time()-tic),\n",
    "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
    "        return embeddings\n",
    "\n",
    "    def visualize(self, sent, tokenize=True):\n",
    "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
    "        sent = [self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]\n",
    "\n",
    "        if len(sent) == 2 and sent[0] == self.bos and sent[1] == self.eos:\n",
    "            import warnings\n",
    "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
    "        \n",
    "        batch = self.get_batch([sent])\n",
    "        \n",
    "        if self.is_cuda():\n",
    "            batch = batch.cuda()\n",
    "        output = self.forward((batch, torch.tensor([len(sent)]).cuda() if self.is_cuda() else torch.tensor([len(sent)])))\n",
    "        output, idxs = torch.max(output, dim=1)\n",
    "        \n",
    "        idxs = idxs.cpu().numpy()\n",
    "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent))]\n",
    "\n",
    "        # visualize model\n",
    "        import matplotlib.pyplot as plt\n",
    "        x = range(len(sent))\n",
    "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
    "        plt.xticks(x, sent, rotation=45)\n",
    "        plt.bar(x, y)\n",
    "        plt.ylabel('%')\n",
    "        plt.title('Visualisation of words importance')\n",
    "        plt.show()\n",
    "\n",
    "        return output, idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization successful using spaCy!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "# Încarcă modelul de limbă în spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_sentence_spacy(sentence, tokenize=True):\n",
    "    if tokenize:\n",
    "        doc = nlp(sentence.lower())\n",
    "        return [token.text for token in doc]\n",
    "    else:\n",
    "        return sentence.lower().split()\n",
    "\n",
    "# Încarcă setul de date\n",
    "data = pd.read_csv(r'C:\\facultate an 3\\projects-simquery\\data\\sts_train.csv', delimiter='\\t')\n",
    "\n",
    "# Filtrează datele pentru a elimina rândurile cu valori lipsă\n",
    "data = data.dropna(subset=['sent_1', 'sent_2', 'sim'])\n",
    "\n",
    "# Extrage propozițiile și scorurile\n",
    "sentences_1 = data['sent_1'].tolist()\n",
    "sentences_2 = data['sent_2'].tolist()\n",
    "similarities = data['sim'].tolist()\n",
    "\n",
    "# Tokenizează propozițiile folosind spaCy\n",
    "sentences_1 = [preprocess_sentence_spacy(s) for s in sentences_1]\n",
    "sentences_2 = [preprocess_sentence_spacy(s) for s in sentences_2]\n",
    "\n",
    "print(\"Tokenization successful using spaCy!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimilarityDataset(Dataset):\n",
    "    def __init__(self, sentences1, sentences2, similarities, word_vec):\n",
    "        self.sentences1 = sentences1\n",
    "        self.sentences2 = sentences2\n",
    "        self.similarities = similarities\n",
    "        self.word_vec = word_vec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.similarities)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        premise = self.sentences1[idx]\n",
    "        hypothesis = self.sentences2[idx]\n",
    "        similarity = self.similarities[idx]\n",
    "        \n",
    "        # Convertim propozițiile în vectori\n",
    "        premise_np = np.array([self.word_vec.get(word, self.word_vec.get('<unk>', np.zeros(300))) for word in premise], dtype='float32')\n",
    "        hypothesis_np = np.array([self.word_vec.get(word, self.word_vec.get('<unk>', np.zeros(300))) for word in hypothesis], dtype='float32')\n",
    "        \n",
    "        premise_tensor = torch.from_numpy(premise_np).float()\n",
    "        hypothesis_tensor = torch.from_numpy(hypothesis_np).float()\n",
    "        similarity_tensor = torch.tensor(similarity, dtype=torch.float)\n",
    "        \n",
    "        return premise_tensor, hypothesis_tensor, similarity_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def collate_fn(batch):\n",
    "    premises, hypotheses, similarities = zip(*batch)\n",
    "    \n",
    "    # Pad propozițiile\n",
    "    premises_padded = nn.utils.rnn.pad_sequence(premises, batch_first=True)\n",
    "    hypotheses_padded = nn.utils.rnn.pad_sequence(hypotheses, batch_first=True)\n",
    "    \n",
    "    # Calculează lungimile\n",
    "    lengths_premises = torch.tensor([len(p) for p in premises], dtype=torch.long)\n",
    "    lengths_hypotheses = torch.tensor([len(h) for h in hypotheses], dtype=torch.long)\n",
    "    \n",
    "    similarities = torch.tensor(similarities, dtype=torch.float)\n",
    "    \n",
    "    return premises_padded, lengths_premises, hypotheses_padded, lengths_hypotheses, similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100002\n",
      "Vocab size : 100002\n",
      "Modelul este pe CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Configurarea modelului\n",
    "model_version = 1  # 1 pentru GloVe, 2 pentru fastText\n",
    "W2V_PATH = r\"C:\\facultate an 3\\projects-simquery\\GloVe\\glove.840B.300d.txt\" if model_version == 1 else r\"C:\\facultate an 3\\projects-simquery\\fastText\\crawl-300d-2M.vec\"\n",
    "\n",
    "params_model = {\n",
    "    'bsize': 64,\n",
    "    'word_emb_dim': 300,\n",
    "    'enc_lstm_dim': 256,\n",
    "    'pool_type': 'mean',\n",
    "    'dpout_model': 0.3,\n",
    "    'version': model_version\n",
    "}\n",
    "\n",
    "# Inițializarea modelului\n",
    "model = InferSent(params_model)\n",
    "model.set_w2v_path(W2V_PATH)\n",
    "\n",
    "# Construiește vocabularul cu K cele mai frecvente cuvinte\n",
    "K = 100000\n",
    "model.build_vocab_k_words(K=K)\n",
    "print(f\"Vocab size : {len(model.word_vec)}\")\n",
    "\n",
    "# Adaugă token-ul '<unk>' dacă nu este deja în vocabular\n",
    "if '<unk>' not in model.word_vec:\n",
    "    model.word_vec['<unk>'] = np.zeros(params_model['word_emb_dim'], dtype='float32')  # Sau poți folosi un vector aleator\n",
    "\n",
    "# Mută modelul pe GPU (dacă este disponibil)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    print(\"Modelul este pe GPU.\")\n",
    "else:\n",
    "    print(\"Modelul este pe CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Împărțirea datelor în seturi de antrenament și validare\n",
    "train_s1, val_s1, train_s2, val_s2, train_sim, val_sim = train_test_split(\n",
    "    sentences_1, sentences_2, similarities, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Crearea dataset-urilor\n",
    "train_dataset = SimilarityDataset(train_s1, train_s2, train_sim, model.word_vec)\n",
    "val_dataset = SimilarityDataset(val_s1, val_s2, val_sim, model.word_vec)\n",
    "\n",
    "# Crearea DataLoader-elor\n",
    "train_loader = DataLoader(train_dataset, batch_size=params_model['bsize'], shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=params_model['bsize'], shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Oana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kg3fpn6v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-valley-7</strong> at: <a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/kg3fpn6v' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project/runs/kg3fpn6v</a><br/> View project at: <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241111_203904-kg3fpn6v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:kg3fpn6v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\facultate an 3\\projects-simquery\\app\\models\\model_1\\wandb\\run-20241111_204130-tyvr9vww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/tyvr9vww' target=\"_blank\">chocolate-sunset-8</a></strong> to <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/tyvr9vww' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project/runs/tyvr9vww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10: 100%|██████████| 81/81 [00:18<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Avg Training Loss: 1.9835 - MAE: 1.9844 - RMSE: 2.3824 - R2: -1.6472 - Pearson: 0.1136 - Spearman: 0.0731 - Accuracy: 16.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Avg Validation Loss: 1.6133 - MAE: 1.6132 - RMSE: 1.9983 - R2: -0.8489 - Pearson: 0.1478 - Spearman: 0.1197 - Accuracy: 19.48%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10: 100%|██████████| 81/81 [00:19<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Avg Training Loss: 1.5545 - MAE: 1.5537 - RMSE: 1.9031 - R2: -0.6892 - Pearson: 0.1646 - Spearman: 0.1264 - Accuracy: 19.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Avg Validation Loss: 1.4785 - MAE: 1.4784 - RMSE: 1.8148 - R2: -0.5250 - Pearson: 0.1351 - Spearman: 0.1073 - Accuracy: 22.09%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10: 100%|██████████| 81/81 [00:18<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Avg Training Loss: 1.4321 - MAE: 1.4326 - RMSE: 1.7276 - R2: -0.3920 - Pearson: 0.1199 - Spearman: 0.0938 - Accuracy: 19.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Avg Validation Loss: 1.3861 - MAE: 1.3861 - RMSE: 1.6792 - R2: -0.3055 - Pearson: 0.1121 - Spearman: 0.0826 - Accuracy: 20.70%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10: 100%|██████████| 81/81 [00:19<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Avg Training Loss: 1.3643 - MAE: 1.3640 - RMSE: 1.6460 - R2: -0.2637 - Pearson: 0.1266 - Spearman: 0.1081 - Accuracy: 20.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Avg Validation Loss: 1.3831 - MAE: 1.3830 - RMSE: 1.6642 - R2: -0.2823 - Pearson: 0.1443 - Spearman: 0.1078 - Accuracy: 20.17%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10: 100%|██████████| 81/81 [00:18<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Avg Training Loss: 1.3548 - MAE: 1.3549 - RMSE: 1.6366 - R2: -0.2493 - Pearson: 0.1330 - Spearman: 0.1157 - Accuracy: 21.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Avg Validation Loss: 1.3562 - MAE: 1.3561 - RMSE: 1.6324 - R2: -0.2338 - Pearson: 0.1534 - Spearman: 0.1206 - Accuracy: 20.00%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10: 100%|██████████| 81/81 [00:19<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Avg Training Loss: 1.3154 - MAE: 1.3159 - RMSE: 1.5979 - R2: -0.1909 - Pearson: 0.1821 - Spearman: 0.1714 - Accuracy: 22.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Avg Validation Loss: 1.3392 - MAE: 1.3391 - RMSE: 1.6140 - R2: -0.2061 - Pearson: 0.1566 - Spearman: 0.1253 - Accuracy: 20.35%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10: 100%|██████████| 81/81 [00:18<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Avg Training Loss: 1.3161 - MAE: 1.3165 - RMSE: 1.6022 - R2: -0.1973 - Pearson: 0.1743 - Spearman: 0.1622 - Accuracy: 22.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Avg Validation Loss: 1.3260 - MAE: 1.3259 - RMSE: 1.5972 - R2: -0.1812 - Pearson: 0.1676 - Spearman: 0.1392 - Accuracy: 20.00%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10: 100%|██████████| 81/81 [00:18<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Avg Training Loss: 1.3224 - MAE: 1.3227 - RMSE: 1.5993 - R2: -0.1930 - Pearson: 0.1806 - Spearman: 0.1663 - Accuracy: 20.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Avg Validation Loss: 1.3240 - MAE: 1.3239 - RMSE: 1.5944 - R2: -0.1771 - Pearson: 0.1838 - Spearman: 0.1548 - Accuracy: 21.57%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10: 100%|██████████| 81/81 [00:20<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Avg Training Loss: 1.2943 - MAE: 1.2939 - RMSE: 1.5706 - R2: -0.1505 - Pearson: 0.2044 - Spearman: 0.1988 - Accuracy: 22.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Avg Validation Loss: 1.3284 - MAE: 1.3283 - RMSE: 1.5957 - R2: -0.1789 - Pearson: 0.1898 - Spearman: 0.1638 - Accuracy: 19.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10: 100%|██████████| 81/81 [00:18<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Avg Training Loss: 1.2991 - MAE: 1.2998 - RMSE: 1.5830 - R2: -0.1688 - Pearson: 0.2096 - Spearman: 0.2012 - Accuracy: 22.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 9/9 [00:00<00:00, 25.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Avg Validation Loss: 1.3129 - MAE: 1.3127 - RMSE: 1.5803 - R2: -0.1564 - Pearson: 0.2031 - Spearman: 0.1803 - Accuracy: 19.48%\n",
      "Modelul a fost salvat pentru performanță mai bună pe validare.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>Training Accuracy</td><td>▁▅▅▆▆▇█▅▇█</td></tr><tr><td>Training Loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>Training MAE</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>Training Pearson</td><td>▁▅▁▂▂▆▅▆██</td></tr><tr><td>Training R2</td><td>▁▅▇▇██████</td></tr><tr><td>Training RMSE</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>Training Spearman</td><td>▁▄▂▃▃▆▆▆██</td></tr><tr><td>Validation Accuracy</td><td>▁█▄▃▂▃▂▇▁▁</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▂▂▁▁▁▁</td></tr><tr><td>Validation MAE</td><td>█▅▃▃▂▂▁▁▁▁</td></tr><tr><td>Validation Pearson</td><td>▄▃▁▃▄▄▅▇▇█</td></tr><tr><td>Validation R2</td><td>▁▄▆▇▇▇████</td></tr><tr><td>Validation RMSE</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>Validation Spearman</td><td>▄▃▁▃▄▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Training Accuracy</td><td>22.61997</td></tr><tr><td>Training Loss</td><td>1.29913</td></tr><tr><td>Training MAE</td><td>1.29978</td></tr><tr><td>Training Pearson</td><td>0.20963</td></tr><tr><td>Training R2</td><td>-0.16876</td></tr><tr><td>Training RMSE</td><td>1.58299</td></tr><tr><td>Training Spearman</td><td>0.20118</td></tr><tr><td>Validation Accuracy</td><td>19.47826</td></tr><tr><td>Validation Loss</td><td>1.31289</td></tr><tr><td>Validation MAE</td><td>1.31274</td></tr><tr><td>Validation Pearson</td><td>0.20308</td></tr><tr><td>Validation R2</td><td>-0.15638</td></tr><tr><td>Validation RMSE</td><td>1.58033</td></tr><tr><td>Validation Spearman</td><td>0.18031</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-sunset-8</strong> at: <a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/tyvr9vww' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project/runs/tyvr9vww</a><br/> View project at: <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241111_204130-tyvr9vww\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definiția clasei InferSent și alte funcții aici...\n",
    "\n",
    "def calculate_regression_metrics(preds, targets):\n",
    "    \"\"\"\n",
    "    Calculează metricile standard de regresie.\n",
    "    \n",
    "    Args:\n",
    "        preds (list or np.array): Predicțiile modelului.\n",
    "        targets (list or np.array): Valorile reale.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: MAE, RMSE, R2, Pearson, Spearman\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    r2 = r2_score(targets, preds)\n",
    "    pearson = pearsonr(targets, preds)[0]\n",
    "    spearman = spearmanr(targets, preds)[0]\n",
    "    return mae, rmse, r2, pearson, spearman\n",
    "\n",
    "def calculate_accuracy(preds, targets, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculează acuratețea ca procentajul predicțiilor care sunt în interiorul\n",
    "    unui interval definit de threshold față de valorile reale.\n",
    "    \n",
    "    Args:\n",
    "        preds (list or np.array): Predicțiile modelului.\n",
    "        targets (list or np.array): Valorile reale.\n",
    "        threshold (float): Pragul de toleranță.\n",
    "    \n",
    "    Returns:\n",
    "        float: Acuratețea în procente.\n",
    "    \"\"\"\n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    correct = np.abs(preds - targets) <= threshold\n",
    "    accuracy = np.mean(correct) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Restul codului de preprocesare și inițializare a modelului...\n",
    "\n",
    "# Inițializarea wandb\n",
    "wandb.init(\n",
    "    project=\"inferSent-project\",  # Înlocuiește cu numele proiectului tău pe wandb\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 64,\n",
    "        \"model_version\": model_version,\n",
    "        \"word_emb_dim\": params_model['word_emb_dim'],\n",
    "        \"enc_lstm_dim\": params_model['enc_lstm_dim'],\n",
    "        \"pool_type\": params_model['pool_type'],\n",
    "        \"dropout\": params_model['dpout_model'],\n",
    "        \"accuracy_threshold\": 0.5  # Pragul pentru acuratețe\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "num_epochs = config.epochs\n",
    "threshold = config.accuracy_threshold\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Antrenament\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_preds = []\n",
    "    train_targets = []\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        premises_padded, lengths_premises, hypotheses_padded, lengths_hypotheses, similarities = batch\n",
    "        if use_cuda:\n",
    "            premises_padded = premises_padded.cuda()\n",
    "            lengths_premises = lengths_premises.cuda()\n",
    "            hypotheses_padded = hypotheses_padded.cuda()\n",
    "            lengths_hypotheses = lengths_hypotheses.cuda()\n",
    "            similarities = similarities.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Encodează perechea de propoziții\n",
    "        combined = model.encode_sentence_pair(\n",
    "            (premises_padded, lengths_premises),\n",
    "            (hypotheses_padded, lengths_hypotheses)\n",
    "        )\n",
    "        \n",
    "        # Prezice similaritatea\n",
    "        preds = model.regress_similarity(combined)\n",
    "        \n",
    "        # Calculează pierderea\n",
    "        loss = criterion(preds, similarities)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Colectează predicțiile și țintele pentru metrici suplimentare\n",
    "        train_preds.extend(preds.detach().cpu().numpy())\n",
    "        train_targets.extend(similarities.detach().cpu().numpy())\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Calcularea metricilor pentru antrenament\n",
    "    train_mae, train_rmse, train_r2, train_pearson, train_spearman = calculate_regression_metrics(train_preds, train_targets)\n",
    "    train_accuracy = calculate_accuracy(train_preds, train_targets, threshold=threshold)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Avg Training Loss: {avg_train_loss:.4f} - \"\n",
    "          f\"MAE: {train_mae:.4f} - RMSE: {train_rmse:.4f} - \"\n",
    "          f\"R2: {train_r2:.4f} - Pearson: {train_pearson:.4f} - \"\n",
    "          f\"Spearman: {train_spearman:.4f} - Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Logare metrici în wandb pentru antrenament\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Training Loss\": avg_train_loss,\n",
    "        \"Training MAE\": train_mae,\n",
    "        \"Training RMSE\": train_rmse,\n",
    "        \"Training R2\": train_r2,\n",
    "        \"Training Pearson\": train_pearson,\n",
    "        \"Training Spearman\": train_spearman,\n",
    "        \"Training Accuracy\": train_accuracy\n",
    "    })\n",
    "    \n",
    "    # Validare\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            premises_padded, lengths_premises, hypotheses_padded, lengths_hypotheses, similarities = batch\n",
    "            if use_cuda:\n",
    "                premises_padded = premises_padded.cuda()\n",
    "                lengths_premises = lengths_premises.cuda()\n",
    "                hypotheses_padded = hypotheses_padded.cuda()\n",
    "                lengths_hypotheses = lengths_hypotheses.cuda()\n",
    "                similarities = similarities.cuda()\n",
    "            \n",
    "            combined = model.encode_sentence_pair(\n",
    "                (premises_padded, lengths_premises),\n",
    "                (hypotheses_padded, lengths_hypotheses)\n",
    "            )\n",
    "            preds = model.regress_similarity(combined)\n",
    "            loss = criterion(preds, similarities)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Colectează predicțiile și țintele pentru metrici suplimentare\n",
    "            val_preds.extend(preds.detach().cpu().numpy())\n",
    "            val_targets.extend(similarities.detach().cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    # Calcularea metricilor pentru validare\n",
    "    val_mae, val_rmse, val_r2, val_pearson, val_spearman = calculate_regression_metrics(val_preds, val_targets)\n",
    "    val_accuracy = calculate_accuracy(val_preds, val_targets, threshold=threshold)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Avg Validation Loss: {avg_val_loss:.4f} - \"\n",
    "          f\"MAE: {val_mae:.4f} - RMSE: {val_rmse:.4f} - \"\n",
    "          f\"R2: {val_r2:.4f} - Pearson: {val_pearson:.4f} - \"\n",
    "          f\"Spearman: {val_spearman:.4f} - Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Logare metrici în wandb pentru validare\n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Validation Loss\": avg_val_loss,\n",
    "        \"Validation MAE\": val_mae,\n",
    "        \"Validation RMSE\": val_rmse,\n",
    "        \"Validation R2\": val_r2,\n",
    "        \"Validation Pearson\": val_pearson,\n",
    "        \"Validation Spearman\": val_spearman,\n",
    "        \"Validation Accuracy\": val_accuracy\n",
    "    })\n",
    "    \n",
    "    # Salvează modelul dacă pierderea pe validare este mai mică\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        model_path = f\"infersent{model_version}_best.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Modelul a fost salvat pentru performanță mai bună pe validare.\")\n",
    "        \n",
    "        # Salvează modelul în wandb folosind Artifacts\n",
    "        artifact = wandb.Artifact('best_model', type='model')\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "# Închide wandb la finalul antrenamentului\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\facultate an 3\\projects-simquery\\app\\models\\model_1\\wandb\\run-20241111_204454-7ccvmuix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/7ccvmuix' target=\"_blank\">light-universe-9</a></strong> to <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stud_ai_bbu/inferSent-project' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stud_ai_bbu/inferSent-project/runs/7ccvmuix' target=\"_blank\">https://wandb.ai/stud_ai_bbu/inferSent-project/runs/7ccvmuix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CommError",
     "evalue": "artifact 'best_model:model' not found in 'stud_ai_bbu/inferSent-project'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\apis\\normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1174\u001b[0m, in \u001b[0;36mApi.artifact\u001b[1;34m(self, name, type)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_entity\n\u001b[1;32m-> 1174\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArtifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m artifact\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m:\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\sdk\\artifacts\\artifact.py:296\u001b[0m, in \u001b[0;36mArtifact._from_name\u001b[1;34m(cls, entity, project, name, client, organization)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs:\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_attrs(entity, project, name, attrs, client)\n",
      "\u001b[1;31mValueError\u001b[0m: artifact 'best_model:model' not found in 'stud_ai_bbu/inferSent-project'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSent-project\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Folosește Artifact-ul pentru a descărca modelul\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model:model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 'model' este tipul Artifact-ului specificat anterior\u001b[39;00m\n\u001b[0;32m     10\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m artifact\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Încarcă starea modelului\u001b[39;00m\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:403\u001b[0m, in \u001b[0;36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Run], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m     default_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m     )\n\u001b[0;32m    409\u001b[0m     resolved_message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:393\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:3078\u001b[0m, in \u001b[0;36mRun.use_artifact\u001b[1;34m(self, artifact_or_name, type, aliases, use_as)\u001b[0m\n\u001b[0;32m   3076\u001b[0m     name \u001b[38;5;241m=\u001b[39m artifact_or_name\n\u001b[0;32m   3077\u001b[0m public_api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_public_api()\n\u001b[1;32m-> 3078\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mpublic_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m artifact\u001b[38;5;241m.\u001b[39mtype:\n\u001b[0;32m   3080\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupplied type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not match type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of artifact \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3082\u001b[0m             \u001b[38;5;28mtype\u001b[39m, artifact\u001b[38;5;241m.\u001b[39mtype, artifact\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m   3083\u001b[0m         )\n\u001b[0;32m   3084\u001b[0m     )\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\apis\\normalize.py:87\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CommError(message, err)\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\apis\\normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhoa, you found a bug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     43\u001b[0m     errors \u001b[38;5;241m=\u001b[39m parse_backend_error_messages(error\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\apis\\public\\api.py:1174\u001b[0m, in \u001b[0;36mApi.artifact\u001b[1;34m(self, name, type)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;66;03m# set entity to match the settings since in above code it was potentially set to an org\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m     entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_entity\n\u001b[1;32m-> 1174\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArtifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m artifact\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtype\u001b[39m:\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m specified but this artifact is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1180\u001b[0m     )\n",
      "File \u001b[1;32mc:\\facultate an 3\\projects-simquery\\.venv\\Lib\\site-packages\\wandb\\sdk\\artifacts\\artifact.py:296\u001b[0m, in \u001b[0;36mArtifact._from_name\u001b[1;34m(cls, entity, project, name, client, organization)\u001b[0m\n\u001b[0;32m    294\u001b[0m attrs \u001b[38;5;241m=\u001b[39m project_attrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attrs:\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_attrs(entity, project, name, attrs, client)\n",
      "\u001b[1;31mCommError\u001b[0m: artifact 'best_model:model' not found in 'stud_ai_bbu/inferSent-project'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Reinițializează wandb\n",
    "wandb.init(project=\"inferSent-project\")\n",
    "\n",
    "# Folosește Artifact-ul pentru a descărca modelul\n",
    "artifact = wandb.use_artifact('best_model:model')  # 'model' este tipul Artifact-ului specificat anterior\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Încarcă starea modelului\n",
    "model_path = os.path.join(artifact_dir, 'infersent1_best.pth')  # Asigură-te că numele fișierului este corect\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))  # Schimbă 'cpu' la 'cuda' dacă ai GPU\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
